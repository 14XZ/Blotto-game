{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "scaleAInew7.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yezhengli-Mr9/Blotto-game/blob/master/new7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YpL8T5ZzP99f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch, random,glob\n",
        "import torch.nn as nn\n",
        "import torch.utils as utils\n",
        "from torch.autograd import Variable\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "# import matplotlib as mpl\n",
        "# mpl.use('Qt4Agg')\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import pickle, os, cv2\n",
        "from tqdm import tqdm\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFulrCJoRza3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rgb2gray(I_rgb):\n",
        "  r, g, b = I_rgb[:, :, 0], I_rgb[:, :, 1], I_rgb[:, :, 2]\n",
        "  I_gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
        "  return I_gray"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vz2ofKE5LPDl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%mkdir res\n",
        "%ls res/*.txt\n",
        "%cat res/log_new7*.txt |wc -l\n",
        "%cat res/log_new7*.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMNnAuKkzhwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# %rm circle_gts.pkl\n",
        "# %rm data/*\n",
        "%rm temp*.png\n",
        "%mkdir data\n",
        "%mkdir model\n",
        "# %mv deno_autoencoder_circle_new_epoche_160.pkl model/deno_autoencoder_circle_new_epoche_160.pkl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukV5MrTOQQsA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%ls res/* -alrth|wc -l\n",
        "# %rm model/deno_autoencoder_circle_new7_scale_*_epoche_*.pkl\n",
        "%ls model/* -alrth"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5js_TYOSQCgQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set Hyperparameters\n",
        "epoch = 50\n",
        "batch_size =50 #100 #256\n",
        "learning_rate = 1e-3\n",
        "scale = 2\n",
        "size = 200\n",
        "data_amount = (int(8000/batch_size)+1)*batch_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-aZnZ_KEyZ9w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_log(text):\n",
        "  with open(\"res/log_new7_scale_{:03d}.txt\".format(scale), \"a+\") as f:\n",
        "    f.write(text+'\\n')\n",
        "  print(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kByhMWiUQGxO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skimage.draw import circle_perimeter_aa\n",
        "def draw_circle(img, row, col, rad):\n",
        "    rr, cc, val = circle_perimeter_aa(row, col, rad)\n",
        "    valid = (\n",
        "        (rr >= 0) &\n",
        "        (rr < img.shape[0]) &\n",
        "        (cc >= 0) &\n",
        "        (cc < img.shape[1])\n",
        "    )\n",
        "    img[rr[valid], cc[valid]] = val[valid]\n",
        "\n",
        "def noisy_circle(size, radius, noise):\n",
        "    img = np.zeros((size, size), dtype=np.float)\n",
        "    # Circle\n",
        "    row = np.random.randint(size)\n",
        "    col = np.random.randint(size)\n",
        "    rad = np.random.randint(10, max(10, radius))\n",
        "    draw_circle(img, row, col, rad)\n",
        "    # Noise\n",
        "    img += noise * np.random.rand(*img.shape)\n",
        "    return (row, col, rad), img\n",
        "\n",
        "gts_imgs = []\n",
        "imgs = []\n",
        "fpickle= \"circle_gts.pkl\"\n",
        "if os.path.exists(fpickle):\n",
        "    print(\"LOADING \"+fpickle)\n",
        "    with open(fpickle,'rb') as fp:\n",
        "        gts = pickle.load(fp)\n",
        "    for i in tqdm(range(data_amount)):        \n",
        "        img =  cv2.imread(\"data/{:05d}.png\".format(i))\n",
        "        try:\n",
        "        # img  = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY )\n",
        "          img_ = rgb2gray(img)\n",
        "          img = img_\n",
        "        except:\n",
        "          pass\n",
        "\n",
        "        imgs.append(img[None,:,:])\n",
        "        params = gts[i]\n",
        "        temp = np.zeros((size, size), dtype=np.float)\n",
        "        draw_circle(temp, params[0], params[1], params[2])\n",
        "#         temp = np.uint8(255*temp)\n",
        "#         print(temp.shape)\n",
        "#         print(temp, np.max(temp))\n",
        "#         temp = cv2.cvtColor(temp, cv2.COLOR_RGB2GRAY )\n",
        "        temp =255* temp/np.max(temp)\n",
        "        gts_imgs.append(temp[None,:,:])\n",
        "        \n",
        "else:\n",
        "    gts = []\n",
        "    for i in tqdm(range(data_amount)):\n",
        "        params, img = noisy_circle(size, 50, 2)\n",
        "        # print(\"before\", img.shape)\n",
        "        # img = np.fft.fft2(img) \n",
        "        # img = np.fft.ifft2(img) \n",
        "        # print(i, np.max(img), np.min(img))\n",
        "        # img = img - np.min(img)\n",
        "        img = img *255/  np.max(img)\n",
        "        try:\n",
        "        # img  = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY )\n",
        "          img_ = rgb2gray(img)\n",
        "          img = img_\n",
        "        except:\n",
        "          pass\n",
        "        # print(\"after\", img.shape)\n",
        "        cv2.imwrite(\"data/{:05d}.png\".format(i), img)\n",
        "        img = cv2.imread(\"data/{:05d}.png\".format(i))\n",
        "        gts.append(params)\n",
        "        # img = np.uint8(img)\n",
        "        # img  = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY )\n",
        "        img = rgb2gray(img)\n",
        "        imgs.append(img[None,:,:])\n",
        "        temp = np.zeros((size, size), dtype=np.float)\n",
        "        draw_circle(temp, params[0], params[1], params[2])\n",
        "        temp =255* temp/np.max(temp)\n",
        "#         temp = cv2.cvtColor(np.uint8(255*temp), cv2.COLOR_RGB2GRAY )\n",
        "        gts_imgs.append(temp[None,:,:])\n",
        "\n",
        "    with open(fpickle,'wb') as fp:\n",
        "        pickle.dump(gts,fp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IShOiy4UQZEh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://stackoverflow.com/questions/44429199/how-to-load-a-list-of-numpy-arrays-to-pytorch-dataset-loader\n",
        "\n",
        "tensorImgs = torch.stack([torch.Tensor(img ) for img in imgs[:data_amount-(int(10000/batch_size)+1)*batch_size ]]) # transform to torch tensors\n",
        "tensorGts = torch.stack([torch.Tensor(gt ) for gt in gts_imgs[:data_amount-(int(10000/batch_size)+1)*batch_size]]) # transform to torch tensors\n",
        "\n",
        "my_dataset = torch.utils.data.TensorDataset(tensorImgs,tensorGts ) # create your datset\n",
        "# my_dataloader = utils.data.DataLoader(my_dataset) # create your dataloader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=my_dataset,batch_size=batch_size,shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNqzsP7nQbjd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encoder \n",
        "# torch.nn.Conv2d(in_channels, out_channels, kernel_size,\n",
        "#                 stride=1, padding=0, dilation=1,\n",
        "#                 groups=1, bias=True)\n",
        "# batch x 1 x 28 x 28 -> batch x 512\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Encoder,self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "                        nn.Conv2d(1,16,3,padding=1),   # batch x 16 x 28 x 28\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(16),\n",
        "                        nn.Conv2d(16,32,3,padding=1),   # batch x 16 x 28 x 28\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(32),\n",
        "                        nn.Conv2d(32,32,3,padding=1),  # batch x 32 x 28 x 28\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(32),\n",
        "                        nn.Conv2d(32,32,3,padding=1),  # batch x 32 x 28 x 28\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(32),\n",
        "                        # nn.MaxPool2d(2,2)   # batch x 64 x 14 x 14\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "                        # nn.Conv2d(32,32,3,padding=1),  # batch x 64 x 14 x 14\n",
        "                        # nn.ReLU(),\n",
        "                        # nn.BatchNorm2d(32),\n",
        "                        nn.Conv2d(32,32,3,padding=1),  # batch x 64 x 14 x 14\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(32),\n",
        "                        nn.Conv2d(32,32,3,padding=1),  # batch x 64 x 14 x 14\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(32),\n",
        "                        # nn.MaxPool2d(2,2),\n",
        "                        nn.Conv2d(32,32,3,padding=1),  # batch x 64 x 7 x 7\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(32),\n",
        "                        nn.Conv2d(32,32,3,padding=1),  # batch x 64 x 14 x 14\n",
        "                        nn.ReLU()\n",
        "        )\n",
        "                \n",
        "    def forward(self,x):\n",
        "        # print(\"[encoder] x.size()\",x.size())\n",
        "        out = self.layer1(x)\n",
        "        # print(\"[encoder] 1out.size()\",out.size())\n",
        "        out = self.layer2(out)\n",
        "        # print(\"[encoder] out.size()\",out.size(), 128*int(size/scale)*int(size/scale), int(size/scale), size, scale)\n",
        "        out = out.view(-1,32*int(size/scale)*int(size/scale))\n",
        "        return out\n",
        "    \n",
        "encoder = Encoder().cuda()#cpu()# #yezheng"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mMgM2O_QdwM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Decoder \n",
        "# torch.nn.ConvTranspose2d(in_channels, out_channels, kernel_size,\n",
        "#                          stride=1, padding=0, output_padding=0,\n",
        "#                          groups=1, bias=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# https://zhuanlan.zhihu.com/p/39240159\n",
        "# output_height = (height-1)*stride + kernel_size - 2*padding + output_padding\n",
        "# output_size = (input_size-1) * stride + outputpadding -2*padding + kernel_size\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Decoder,self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "                        # nn.ConvTranspose2d(32,32,3,2,1,1),\n",
        "                        # nn.ReLU(),\n",
        "                        # nn.BatchNorm2d(32),\n",
        "                        nn.ConvTranspose2d(32,32,3,2,1,1),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(32),\n",
        "                        nn.ConvTranspose2d(32,32,3,2,1,1),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(32),\n",
        "                        nn.ConvTranspose2d(32,32,3,1,1),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(32),\n",
        "                        nn.ConvTranspose2d(32,32,3,1,1),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(32),\n",
        "                        nn.ConvTranspose2d(32,32,3,1,1),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(32),\n",
        "                        nn.MaxPool2d(8,8)\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "                        nn.ConvTranspose2d(32,32,3,1,1),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(32),\n",
        "                        nn.ConvTranspose2d(32,16,3,1,1),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(16),\n",
        "                        nn.ConvTranspose2d(16,1,3,2,1,1),\n",
        "                        nn.ReLU(),\n",
        "        )\n",
        "        \n",
        "        \n",
        "    def forward(self,x):\n",
        "        out = x.view(-1,32,round(size/scale),round(size/scale))\n",
        "        # print(\"[decoder] out.size()\", out.size())\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        return out\n",
        "\n",
        "decoder = Decoder().cuda()#cpu() #yezheng"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyJb8QZVQkbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loss func and optimizer\n",
        "# we compute reconstruction after decoder so use Mean Squared Error\n",
        "# In order to use multi parameters with one optimizer,\n",
        "# concat parameters after changing into list\n",
        "\n",
        "parameters = list(encoder.parameters())+ list(decoder.parameters())\n",
        "loss_func = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(parameters, lr=learning_rate)\n",
        "print(len(parameters ))\n",
        "num_parameters = 0\n",
        "for p in parameters:\n",
        "  print(p.shape)\n",
        "  r = 1\n",
        "  for f in  list(p.shape):\n",
        "    r*=f\n",
        "  num_parameters+=r\n",
        "print(num_parameters)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOjfAZ_eQm0d",
        "colab_type": "code",
        "outputId": "f845208e-7fa9-4a77-a886-71b3f1801b9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        }
      },
      "source": [
        "# train encoder and decoder\n",
        "# save and load model\n",
        "max_epoch = 0\n",
        "for md_para_save_name in glob.glob('model/deno_autoencoder_circle_new7_scale_*_epoche_*.pkl'): \n",
        "  max_epoch = max(max_epoch,int(md_para_save_name.split('_')[-1][:-4]))\n",
        "if 0 == max_epoch:\n",
        "  print(\"\\n--------model not restored--------\\n\")\n",
        "else:\n",
        "  encoder, decoder = torch.load('model/deno_autoencoder_circle_new7_scale_{:03d}_epoche_{:03d}.pkl'.format(scale,max_epoch))\n",
        "  print(\"\\n--------model restored--------\\n\")\n",
        "# \n",
        "\n",
        "Half = nn.Upsample(scale_factor=1/scale, mode='bilinear')\n",
        "Double = nn.Upsample(scale_factor=scale, mode='bilinear')\n",
        "from time import time\n",
        "T0 = time()\n",
        "for i in tqdm(range(max_epoch+1, max_epoch+ epoch+1)):#+ epoch+1\n",
        "#     List = random.choices(range(1000), k=batch_size)\n",
        "#     for j in List:\n",
        "    for image_n,img_gt in train_loader:\n",
        "#         image_n = torch.tensor(imgs[j])\n",
        "#         img_gt = torch.tensor(gts_imgs[j])\n",
        "        # print(image_n.size(), img_gt.size())\n",
        "        image_n = Half(Variable(image_n).cuda()) #cpu()#yezheng\n",
        "        img_gt = Half(Variable(img_gt).cuda() ) #cpu() #yezheng        \n",
        "        #label = Variable(label.float()).cpu()#.cuda() #yezheng\n",
        "        optimizer.zero_grad()\n",
        "        output = encoder(image_n)\n",
        "        output = decoder(output)\n",
        "        # print(output.size(), image_n.size())\n",
        "        loss = loss_func(output,img_gt)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "                \n",
        "    if i%10 == 0: \n",
        "      torch.save([encoder,decoder],'model/deno_autoencoder_circle_new7_scale_{:03d}_epoche_{:03d}.pkl'.format(scale,i))\n",
        "      max_epoch = max(max_epoch, i)\n",
        "    print_log(\"epoch \"+str(i)+\" loss \"+str(loss)+\" learning_rate \"+str(learning_rate)+' batch_size '+str(batch_size) + \" time \"+str(time() - T0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Encoder. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Sequential. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Conv2d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ReLU. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type BatchNorm2d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Decoder. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type ConvTranspose2d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type MaxPool2d. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
            "\r 20%|██        | 10/50 [16:05<1:04:23, 96.58s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 10 loss tensor(14.0781, device='cuda:0', grad_fn=<MseLossBackward>) learning_rate 0.001 batch_size 50 time 965.8371126651764\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 22%|██▏       | 11/50 [17:42<1:02:46, 96.58s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 11 loss tensor(12.8026, device='cuda:0', grad_fn=<MseLossBackward>) learning_rate 0.001 batch_size 50 time 1062.4144484996796\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3XABtkJQoxc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%mkdir res \n",
        "%rm res/*.png\n",
        "# check image with noise and denoised image\\n# Better image if you train more or upgrade the model\\n\n",
        "from copy import deepcopy\n",
        "imgs = []\n",
        "for img_idx in tqdm(range(data_amount-(int(100/batch_size)+1)*batch_size,data_amount)):\n",
        "    # print(\"data/{:05d}.png\".format(img_idx))\n",
        "    img = cv2.imread(\"data/{:05d}.png\".format(img_idx))\n",
        "    try:\n",
        "    # img  = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY )\n",
        "      img_ = rgb2gray(img)\n",
        "      img = img_\n",
        "    except:\n",
        "      pass\n",
        "    # print(img.shape)\n",
        "    imgs.append(img)\n",
        "    input_img = torch.tensor(cv2.resize(img, (int(size/scale),int(size/scale ) ) )[None,None,:,:] )\n",
        "    input_img = input_img.float().cuda()\n",
        "    # print(input_img.size() )\n",
        "    output_img = decoder(encoder(input_img))\n",
        "    output_img = Double(output_img)\n",
        "    inp = input_img.data.cpu().numpy()[0,0,:,:]\n",
        "    out = output_img.data.cpu().numpy()[0,0,:,:]\n",
        "    out = cv2.resize(out, (size,size))\n",
        "    out =255-255*out/np.max(out)\n",
        "    # print(np.max(out ))\n",
        "    gt = gts_imgs[img_idx][0,:,:]\n",
        "    # circles = cv2.HoughCircles(np.uint8(out),cv2.HOUGH_GRADIENT,1,20, param1=100,param2=80,minRadius=0,maxRadius=0)\n",
        "    # circles = cv2.HoughCircles(np.uint8(out),cv2.HOUGH_GRADIENT,0.1,20, param1=200,param2=80,minRadius=0,maxRadius=0)\n",
        "    # circles = cv2.HoughCircles(np.uint8(out),cv2.HOUGH_GRADIENT,1e-10,300)\n",
        "    circles = cv2.HoughCircles(np.uint8(out),cv2.HOUGH_GRADIENT,1,20, param1=100,param2=30, minRadius = 0, maxRadius = 2*size)#,minRadius=0,maxRadius=0\n",
        "    output = cv2.imread(\"data/{:05d}.png\".format(img_idx))#cv2.resize(deepcopy(inp),(size,size))\n",
        "    # ensure at least some circles were found\n",
        "    if circles is not None:\n",
        "      # convert the (x, y) coordinates and radius of the circles to integers\n",
        "      # circles = np.round(circles[0, :]).astype(\"int\")\n",
        "      circles = np.uint16(np.around(circles))\n",
        "    \n",
        "      # loop over the (x, y) coordinates and radius of the circles\n",
        "      for i in circles[0,:]:\n",
        "        # draw the circle in the output image, then draw a rectangle\n",
        "        # corresponding to the center of the circle\n",
        "        cv2.circle(output,(i[0],i[1]),i[2],(0,255,0),2)\n",
        "      # draw the center of the circle\n",
        "        cv2.circle(output,(i[0],i[1]),2,(0,0,255),3)\n",
        "\n",
        "    fig, (Ax_gt, Ax_img, Ax_out,Ax_circle) = plt.subplots(1,4, figsize = (20, 8))\n",
        "        \n",
        "    Ax_gt.imshow(gt, interpolation='nearest')\n",
        "    Ax_gt.axis('off')\n",
        "    Ax_gt.set_title('gt')\n",
        "\n",
        "    Ax_img.imshow(img, cmap='gray', interpolation='nearest')\n",
        "    Ax_img.axis('off')\n",
        "    Ax_img.set_title('original image')\n",
        "\n",
        "    Ax_out.imshow(out, cmap='gray', interpolation='nearest')\n",
        "    Ax_out.axis('off')\n",
        "    Ax_out.set_title('out')\n",
        "\n",
        "    Ax_circle.imshow(output, cmap='gray', interpolation='nearest')\n",
        "    Ax_circle.axis('off')\n",
        "    Ax_circle.set_title('Circle')\n",
        "    fig.savefig(\"res/res_{:05d}.png\".format(img_idx))\n",
        "    # plt.show(output)\n",
        "    if 0!= img_idx%50:\n",
        "      plt.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgWKCbKMvu_y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"success\",success)\n",
        "%ls res/* -alrth|wc -l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5R_ruQ2McF3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#!/usr/bin/env python\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "def zipdir(path, ziph):\n",
        "    # ziph is zipfile handle\n",
        "    for root, dirs, files in os.walk(path):\n",
        "        for file in files:\n",
        "            ziph.write(os.path.join(root, file))\n",
        "\n",
        "\n",
        "zipf = zipfile.ZipFile('res.zip', 'w', zipfile.ZIP_DEFLATED)\n",
        "zipdir('res/', zipf)\n",
        "zipf.close()\n",
        "\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "files.download('res.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKUaoMp6-wmZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#!/usr/bin/env python\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "def zipdir(path, ziph):\n",
        "    # ziph is zipfile handle\n",
        "    for root, dirs, files in os.walk(path):\n",
        "        for file in files:\n",
        "            ziph.write(os.path.join(root, file))\n",
        "\n",
        "\n",
        "zipf = zipfile.ZipFile('model.zip', 'w', zipfile.ZIP_DEFLATED)\n",
        "zipdir('model/', zipf)\n",
        "zipf.close()\n",
        "\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "files.download('model.zip')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raN1IGk5GVkO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# max_epoch = 160\n",
        "# files.download('model/deno_autoencoder_circle_scale_{:03d}_new7_epoche_{:03d}.pkl'.format(scale,max_epoch))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEEKjqSgR5Tu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "# for fn in uploaded.keys():\n",
        "#   print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "#       name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9TUaCo0RUHO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encoder \n",
        "import torch.nn as nn\n",
        "import torch\n",
        "size = 200\n",
        "batch_size = 100\n",
        "scale = 4\n",
        "Half = nn.Upsample(scale_factor=1/2, mode='bilinear')\n",
        "Double = nn.Upsample(scale_factor=2, mode='bilinear')\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Encoder,self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "                        nn.Conv2d(1,32,3,padding=1),  \n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(32),\n",
        "                        nn.Conv2d(32,32,3,padding=1), \n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(32),\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "                        nn.Conv2d(32,64,3,padding=1),  \n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(64),\n",
        "                        nn.ReLU()\n",
        "        )\n",
        "        \n",
        "                \n",
        "    def forward(self,x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "#         print(\"[encoder] out.size()\",out.size())\n",
        "        out = out.view(batch_size, -1)\n",
        "        return out\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Decoder \n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Decoder,self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "                        nn.ConvTranspose2d(64,32,3,stride=2,padding=1,output_padding = 1),\n",
        "                        nn.ReLU(),\n",
        "                        nn.BatchNorm2d(32),\n",
        "                        nn.ConvTranspose2d(32,32,3,stride = 1,padding= 1),\n",
        "                        nn.ReLU(),\n",
        "                        nn.ReLU(),\n",
        "                        nn.MaxPool2d(2,2)\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "                        nn.ConvTranspose2d(32,1,5,stride= 2,padding=1,output_padding=1),\n",
        "                        nn.ReLU(),\n",
        "                        nn.MaxPool2d(2,2)\n",
        "\n",
        "        )\n",
        "        \n",
        "    def forward(self,x):\n",
        "        out = x.view(-1,64,int(size/scale),int(size/scale))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        return out\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aeg0X0ZBTb48",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from shapely.geometry.point import Point\n",
        "from skimage.draw import circle_perimeter_aa\n",
        "import matplotlib.pyplot as plt\n",
        "# from autoencoder import encoder, decoder, size, scale, device\n",
        "import cv2, torch\n",
        "def draw_circle(img, row, col, rad):\n",
        "    rr, cc, val = circle_perimeter_aa(row, col, rad)\n",
        "    valid = (\n",
        "        (rr >= 0) &\n",
        "        (rr < img.shape[0]) &\n",
        "        (cc >= 0) &\n",
        "        (cc < img.shape[1])\n",
        "    )\n",
        "    img[rr[valid], cc[valid]] = val[valid]\n",
        "\n",
        "\n",
        "def noisy_circle(size, radius, noise):\n",
        "    img = np.zeros((size, size), dtype=np.float)\n",
        "    # Circle\n",
        "    row = np.random.randint(size)\n",
        "    col = np.random.randint(size)\n",
        "    rad = np.random.randint(10, max(10, radius))\n",
        "    draw_circle(img, row, col, rad)\n",
        "    # Noise\n",
        "    img += noise * np.random.rand(*img.shape)\n",
        "    return (row, col, rad), img\n",
        "\n",
        "\n",
        "def find_circle(img,idx):\n",
        "    try:\n",
        "      del out\n",
        "    except:\n",
        "      pass\n",
        "    cv2.imwrite(\"temp_{:04d}.png\".format(idx), img)\n",
        "    input_img = torch.tensor(cv2.resize(img, (int(size/scale),int(size/scale ) ) )[None,None,:,:] )\n",
        "    input_img = input_img.float()\n",
        "    if 'cuda' == device.type:\n",
        "        input_img = input_img.cuda()\n",
        "    # print(input_img.size() )\n",
        "    output_img = decoder(encoder(input_img))\n",
        "    output_img = Double(output_img)\n",
        "    inp = input_img.data.cpu().numpy()[0,0,:,:]\n",
        "    inp = input_img.data.cpu().numpy()[0,0,:,:]\n",
        "    out = output_img.data.cpu().numpy()[0,0,:,:]\n",
        "    out = cv2.resize(out, (size,size))\n",
        "    # output = img[:,None,None]\n",
        "    # print('---------')\n",
        "    output = cv2.imread(\"temp_{:04d}.png\".format(idx))\n",
        "    os.remove(\"temp_{:04d}.png\".format(idx))\n",
        "    out =255-255*out/np.max(out)\n",
        "    circles = cv2.HoughCircles(np.uint8(out),cv2.HOUGH_GRADIENT,1,20, param1=100,param2=30, minRadius = 0, maxRadius = 2*size)#,minRadius=0,maxRadius=0\n",
        "    # print(\"circles\", circles)\n",
        "    if circles is not None:\n",
        "      # circles = np.round(circles[0, :]).astype(\"int\")\n",
        "      circles = np.uint16(np.around(circles))\n",
        "      # Fill in this function\n",
        "      # print(idx,[row,col,rad])\n",
        "  \n",
        "      row,col,rad = circles[0][0]\n",
        "     \n",
        "    else:\n",
        "      row,col,rad = 100,100,30\n",
        "# convert the (x, y) coordinates and radius of the circles to integers\n",
        "    \n",
        "    # draw the circle in the output image, then draw a rectangle\n",
        "    # corresponding to the center of the circle\n",
        "    cv2.circle(output,(row,col),rad,(0,255,0),2)\n",
        "    # draw the center of the circle\n",
        "    cv2.circle(output,(row,col),2,(0,0,255),3)\n",
        "\n",
        "    fig, ( Ax_img, Ax_out,Ax_circle) = plt.subplots(1,3, figsize = (20, 8))\n",
        "      \n",
        "    # Ax_gt.imshow(gt, interpolation='nearest')\n",
        "    # Ax_gt.axis('off')\n",
        "    # Ax_gt.set_title('gt')\n",
        "\n",
        "    Ax_img.imshow(img, cmap='gray', interpolation='nearest')\n",
        "    Ax_img.axis('off')\n",
        "    Ax_img.set_title('original image')\n",
        "\n",
        "    Ax_out.imshow(out, cmap='gray', interpolation='nearest')\n",
        "    Ax_out.axis('off')\n",
        "    Ax_out.set_title('out')\n",
        "\n",
        "    Ax_circle.imshow(output, cmap='gray', interpolation='nearest')\n",
        "    Ax_circle.axis('off')\n",
        "    Ax_circle.set_title('Circle')\n",
        "    # print(\"type(idx)\",idx)\n",
        "    fig.savefig(\"res/res_{:04d}.png\".format(idx))\n",
        "    \n",
        "    \n",
        "    return row,col,rad\n",
        "    \n",
        "\n",
        "def iou(params0, params1):\n",
        "    row0, col0, rad0 = params0\n",
        "    row1, col1, rad1 = params1\n",
        "\n",
        "    shape0 = Point(row0, col0).buffer(rad0)\n",
        "    shape1 = Point(row1, col1).buffer(rad1)\n",
        "\n",
        "    return (\n",
        "        shape0.intersection(shape1).area /\n",
        "        shape0.union(shape1).area\n",
        "    )\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FH6DC9fTRaPw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = []\n",
        "model_paras_saved= 'model/deno_autoencoder_circle_new_epoche_{:03d}.pkl'.format(160)\n",
        "if 'cuda' == device.type:\n",
        "    encoder, decoder  =torch.load(model_paras_saved)\n",
        "else:\n",
        "    encoder, decoder  =torch.load(model_paras_saved, map_location=lambda storage, location: storage)\n",
        "for idx in range(1000):\n",
        "    params, img = noisy_circle(200, 50, 2)\n",
        "    detected = find_circle(img,idx)\n",
        "    # print(params,detected)\n",
        "    results.append(iou(params, detected))\n",
        "results = np.array(results)\n",
        "print((results > 0.7).mean())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-FUAoxMb12R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = np.array(results)\n",
        "print((results > 0.7).mean())"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}